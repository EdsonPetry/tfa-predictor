{
  "input_size": 3883,
  "output_size": 214,
  "hidden_sizes": [
    4096,
    2048,
    1024
  ],
  "lr": 0.000485228371808412,
  "weight_decay": 0.00017090271242320003,
  "batch_size": 32,
  "max_epochs": 200,
  "dropout_rate": 0.3938949443572462,
  "activation": "leaky_relu",
  "optimizer": "adam",
  "learning_rate_schedule": "cosine",
  "batch_norm": "true"
}