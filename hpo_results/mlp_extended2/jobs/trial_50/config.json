{
  "input_size": 3883,
  "output_size": 214,
  "hidden_sizes": [
    4096,
    2048,
    1024,
    512
  ],
  "lr": 0.0005795489179735745,
  "weight_decay": 3.3104189563245155e-06,
  "batch_size": 16,
  "max_epochs": 500,
  "dropout_rate": 0.12512144908229766,
  "activation": "leaky_relu",
  "optimizer": "adamw",
  "learning_rate_schedule": "exponential",
  "batch_norm": "true"
}