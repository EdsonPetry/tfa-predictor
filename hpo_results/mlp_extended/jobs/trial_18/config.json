{
  "input_size": 3883,
  "output_size": 214,
  "hidden_sizes": [
    3072,
    1536,
    768,
    384
  ],
  "lr": 0.010506596753220968,
  "weight_decay": 4.149795789891592e-05,
  "batch_size": 32,
  "max_epochs": 200,
  "dropout_rate": 0.17814891903848745,
  "activation": "leaky_relu",
  "optimizer": "adam",
  "learning_rate_schedule": "none",
  "batch_norm": "true"
}